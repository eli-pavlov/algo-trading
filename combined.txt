// .dockerignore


// .env
APIKEY=<apikey>
SECRETKEY=<secretkey>
REPORT_LINK=<report_link>
PAPER_URL=<paper_url>
DB_PATH=<db_path>

// .flake8
[flake8]
ignore = E501, E302, E305, E722, F401, W292, W291, W293, E701, E225
max-line-length = 120
exclude = .git,__pycache__,env,venv

// .github/workflows/lint.yml
name: Code Quality Gate
on: [push, pull_request]

jobs:
  lint:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.9"
      - name: Install dependencies
        run: pip install flake8
      - name: Run Linting
        # If this fails, the whole Action fails
        run: flake8 src/ --count --max-line-length=120

// .gitignore
Ôªø# Python artifacts
__pycache__/
*.pyc
env/
venv/

# Environment Variables
.env
.env.*

# Logs & Data
*.log
logs/
*.db
*.sqlite
cache/

# IDE
.vscode/
.idea/

# Strategies and settings
strategies.yaml
settings.yaml
fine_tuner.*
market_scanner.*

// config/strategies.yaml


// docker-compose.yaml
version: '3.8'
services:
  trading-bot:
    image: algo-trader
    container_name: algo_heart
    restart: always
    env_file: .env
    network_mode: "host"
    volumes:
      - ./data:/app/data
    # --- NEW SECTION: Unlock Memory ---
    deploy:
      resources:
        limits:
          memory: 3G  # Allow up to 4GB
        reservations:
          memory: 1G  # Guarantee at least 1GB
    # ----------------------------------
    healthcheck:
      test: ["CMD-SHELL", "find /tmp/heartbeat -mmin -2 | grep . || exit 1"]
      interval: 1m
      retries: 3

  dashboard:
    image: algo-trader
    container_name: algo_ui
    restart: always
    network_mode: "host"
    env_file: .env
    volumes:
      - ./data:/app/data
    command: streamlit run src/dashboard.py --server.port=8501 --server.address=0.0.0.0

// Dockerfile
FROM python:3.9-slim
WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    gcc g++ ca-certificates \
    && update-ca-certificates \
    && rm -rf /var/lib/apt/lists/*

COPY requirements.txt .

# Install dependencies with trusted hosts
# We use --network=host in the build command, so this should fly now
RUN pip install --no-cache-dir \
    --timeout 100 \
    --trusted-host pypi.org \
    --trusted-host pypi.python.org \
    --trusted-host files.pythonhosted.org \
    -r requirements.txt

COPY . .
ENV PYTHONPATH=/app PYTHONUNBUFFERED=1
CMD ["python", "src/main.py"]

// Jenkinsfile
pipeline {
    agent any
    environment {
        // This variable isn't strictly needed anymore but good for reference
        DOCKER_IMAGE = "algo-trader"
    }
    stages {
        stage('Checkout') {
            steps { checkout scm }
        }
        stage('Prepare Secrets') {
            steps {
                withCredentials([file(credentialsId: 'algo-trading-env', variable: 'SECRET_ENV')]) {
                    sh 'cp "$SECRET_ENV" .env'
                }
            }
        }
        stage('Build & Deploy') {
            steps {
                // 1. Build the image using HOST networking
                // This allows pip to connect to PyPI successfully (like your manual test)
                sh "docker build --network=host -t algo-trader ."

                // 2. Start containers using the image we just built
                // We remove orphans to clean up any old containers from previous failed builds
                sh "docker compose up -d --remove-orphans"
                
                // 3. Wait for boot and Train
                sh "sleep 5"
                sh "docker exec algo_heart python src/tuner.py"
                
                // 4. Cleanup dangling images to save disk space
                sh "docker image prune -f"
            }
        }
    }
}

// LICENSE
                                 Apache License
                           Version 2.0, January 2004
                        http://www.apache.org/licenses/

   TERMS AND CONDITIONS FOR USE, REPRODUCTIO  AND DISTRIBUTION

   1. Definitions.

      "License" shall mean the terms and conditions for use, reproduction,
      and distribution as defined by Sections 1 through 9 of this document.

      "Licensor" shall mean the copyright owner or entity authorized by
      the copyright owner that is granting the License.

      "Legal Entity" shall mean the union of the acting entity and all
      other entities that control, are controlled by, or are under common
      control with that entity. For the purposes of this definition,
      "control" means (i) the power, direct or indirect, to cause the
      direction or management of such entity, whether by contract or
      otherwise, or (ii) ownership of fifty percent (50%) or more of the
      outstanding shares, or (iii) beneficial ownership of such entity.

      "You" (or "Your") shall mean an individual or Legal Entity
      exercising permissions granted by this License.

      "Source" form shall mean the preferred form for making modifications,
      including but not limited to software source code, documentation
      source, and configuration files.

      "Object" form shall mean any form resulting from mechanical
      transformation or translation of a Source form, including but
      not limited to compiled object code, generated documentation,
      and conversions to other media types.

      "Work" shall mean the work of authorship, whether in Source or
      Object form, made available under the License, as indicated by a
      copyright notice that is included in or attached to the work
      (an example is provided in the Appendix below).

      "Derivative Works" shall mean any work, whether in Source or Object
      form, that is based on (or derived from) the Work and for which the
      editorial revisions, annotations, elaborations, or other modifications
      represent, as a whole, an original work of authorship. For the purposes
      of this License, Derivative Works shall not include works that remain
      separable from, or merely link (or bind by name) to the interfaces of,
      the Work and Derivative Works thereof.

      "Contribution" shall mean any work of authorship, including
      the original version of the Work and any modifications or additions
      to that Work or Derivative Works thereof, that is intentionally
      submitted to Licensor for inclusion in the Work by the copyright owner
      or by an individual or Legal Entity authorized to submit on behalf of
      the copyright owner. For the purposes of this definition, "submitted"
      means any form of electronic, verbal, or written communication sent
      to the Licensor or its representatives, including but not limited to
      communication on electronic mailing lists, source code control systems,
      and issue tracking systems that are managed by, or on behalf of, the
      Licensor for the purpose of discussing and improving the Work, but
      excluding communication that is conspicuously marked or otherwise
      designated in writing by the copyright owner as "Not a Contribution."

      "Contributor" shall mean Licensor and any individual or Legal Entity
      on behalf of whom a Contribution has been received by Licensor and
      subsequently incorporated within the Work.

   2. Grant of Copyright License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      copyright license to reproduce, prepare Derivative Works of,
      publicly display, publicly perform, sublicense, and distribute the
      Work and such Derivative Works in Source or Object form.

   3. Grant of Patent License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      (except as stated in this section) patent license to make, have made,
      use, offer to sell, sell, import, and otherwise transfer the Work,
      where such license applies only to those patent claims licensable
      by such Contributor that are necessarily infringed by their
      Contribution(s) alone or by combination of their Contribution(s)
      with the Work to which such Contribution(s) was submitted. If You
      institute patent litigation against any entity (including a
      cross-claim or counterclaim in a lawsuit) alleging that the Work
      or a Contribution incorporated within the Work constitutes direct
      or contributory patent infringement, then any patent licenses
      granted to You under this License for that Work shall terminate
      as of the date such litigation is filed.

   4. Redistribution. You may reproduce and distribute copies of the
      Work or Derivative Works thereof in any medium, with or without
      modifications, and in Source or Object form, provided that You
      meet the following conditions:

      (a) You must give any other recipients of the Work or
          Derivative Works a copy of this License; and

      (b) You must cause any modified files to carry prominent notices
          stating that You changed the files; and

      (c) You must retain, in the Source form of any Derivative Works
          that You distribute, all copyright, patent, trademark, and
          attribution notices from the Source form of the Work,
          excluding those notices that do not pertain to any part of
          the Derivative Works; and

      (d) If the Work includes a "NOTICE" text file as part of its
          distribution, then any Derivative Works that You distribute must
          include a readable copy of the attribution notices contained
          within such NOTICE file, excluding those notices that do not
          pertain to any part of the Derivative Works, in at least one
          of the following places: within a NOTICE text file distributed
          as part of the Derivative Works; within the Source form or
          documentation, if provided along with the Derivative Works; or,
          within a display generated by the Derivative Works, if and
          wherever such third-party notices normally appear. The contents
          of the NOTICE file are for informational purposes only and
          do not modify the License. You may add Your own attribution
          notices within Derivative Works that You distribute, alongside
          or as an addendum to the NOTICE text from the Work, provided
          that such additional attribution notices cannot be construed
          as modifying the License.

      You may add Your own copyright statement to Your modifications and
      may provide additional or different license terms and conditions
      for use, reproduction, or distribution of Your modifications, or
      for any such Derivative Works as a whole, provided Your use,
      reproduction, and distribution of the Work otherwise complies with
      the conditions stated in this License.

   5. Submission of Contributions. Unless You explicitly state otherwise,
      any Contribution intentionally submitted for inclusion in the Work
      by You to the Licensor shall be under the terms and conditions of
      this License, without any additional terms or conditions.
      Notwithstanding the above, nothing herein shall supersede or modify
      the terms of any separate license agreement you may have executed
      with Licensor regarding such Contributions.

   6. Trademarks. This License does not grant permission to use the trade
      names, trademarks, service marks, or product names of the Licensor,
      except as required for reasonable and customary use in describing the
      origin of the Work and reproducing the content of the NOTICE file.

   7. Disclaimer of Warranty. Unless required by applicable law or
      agreed to in writing, Licensor provides the Work (and each
      Contributor provides its Contributions) on an "AS IS" BASIS,
      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
      implied, including, without limitation, any warranties or conditions
      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
      PARTICULAR PURPOSE. You are solely responsible for determining the
      appropriateness of using or redistributing the Work and assume any
      risks associated with Your exercise of permissions under this License.

   8. Limitation of Liability. In no event and under no legal theory,
      whether in tort (including negligence), contract, or otherwise,
      unless required by applicable law (such as deliberate and grossly
      negligent acts) or agreed to in writing, shall any Contributor be
      liable to You for damages, including any direct, indirect, special,
      incidental, or consequential damages of any character arising as a
      result of this License or out of the use or inability to use the
      Work (including but not limited to damages for loss of goodwill,
      work stoppage, computer failure or malfunction, or any and all
      other commercial damages or losses), even if such Contributor
      has been advised of the possibility of such damages.

   9. Accepting Warranty or Additional Liability. While redistributing
      the Work or Derivative Works thereof, You may choose to offer,
      and charge a fee for, acceptance of support, warranty, indemnity,
      or other liability obligations and/or rights consistent with this
      License. However, in accepting such obligations, You may act only
      on Your own behalf and on Your sole responsibility, not on behalf
      of any other Contributor, and only if You agree to indemnify,
      defend, and hold each Contributor harmless for any liability
      incurred by, or claims asserted against, such Contributor by reason
      of your accepting any such warranty or additional liability.

   END OF TERMS AND CONDITIONS

   APPENDIX: How to apply the Apache License to your work.

      To apply the Apache License to your work, attach the following
      boilerplate notice, with the fields enclosed by brackets "[]"
      replaced with your own identifying information. (Don't include
      the brackets!)  The text should be enclosed in the appropriate
      comment syntax for the file format. We also recommend that a
      file or class name and description of purpose be included on the
      same "printed page" as the copyright notice for easier
      identification within third-party archives.

   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.

// README.md
Ôªø# algo-trading
Algorithmic Trading Bot Monorepo

// requirements.txt
alpaca-trade-api
krakenex
pykrakenapi
yfinance
pandas
pandas-ta-classic
ta
numpy
python-dotenv
pyyaml
requests
requests-cache
schedule
streamlit
pytest
flake8
optuna
scikit-learn
plotly

// src/broker.py
import os
import requests
import alpaca_trade_api as tradeapi
import urllib3
from datetime import datetime, timezone
# Import the new logging functions
from src.database import log_trade_attempt, update_trade_fill, DB_PATH
import sqlite3

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)


class Broker:
    def __init__(self):
        self.base_url = "https://paper-api.alpaca.markets"
        self.api_key = os.getenv("APIKEY")
        self.secret_key = os.getenv("SECRETKEY")

        self.api = tradeapi.REST(
            key_id=self.api_key,
            secret_key=self.secret_key,
            base_url=self.base_url,
            api_version='v2'
        )
        self.api._session.trust_env = False
        self.api._session.verify = False

    # ... (Keep test_connection, get_market_clock, get_portfolio_history_stats, get_account_stats, get_orders_for_symbol, has_open_order as is) ...
    def test_connection(self):
        try:
            acct = self.api.get_account()
            return True, f"Connected to {acct.id}"
        except Exception as e:
            return False, str(e)

    def get_market_clock(self):
        try:
            clock = self.api.get_clock()
            now = clock.timestamp.replace(tzinfo=timezone.utc)
            if clock.is_open:
                close_time = clock.next_close.replace(tzinfo=timezone.utc)
                diff = close_time - now
                hours, remainder = divmod(diff.seconds, 3600)
                mins, _ = divmod(remainder, 60)
                return f"üü¢ Market Open (Closes in {hours}h {mins}m)"
            else:
                open_time = clock.next_open.replace(tzinfo=timezone.utc)
                diff = open_time - now
                days = diff.days
                hours, remainder = divmod(diff.seconds, 3600)
                mins, _ = divmod(remainder, 60)
                if days > 0:
                    return f"üî¥ Market Closed (Opens in {days} days, {hours}h {mins}m)"
                else:
                    return f"üî¥ Market Closed (Opens in {hours}h {mins}m)"
        except Exception:
            return "üü† Market Status Unavailable"

    def get_portfolio_history_stats(self):
        periods = {'1D': '1D', '1W': '1W', '1M': '1M', '1A': '1A'}
        data = {}
        for label, p in periods.items():
            try:
                hist = self.api.get_portfolio_history(period=p, timeframe="1D")
                if hist.equity:
                    start = hist.equity[0]
                    end = hist.equity[-1]
                    if start == 0: start = 1
                    pct = ((end - start) / start) * 100
                    data[label] = f"{pct:+.2f}%"
                else:
                    data[label] = "0.00%"
            except Exception:
                data[label] = "N/A"
        return data

    def get_account_stats(self):
        try:
            acc = self.api.get_account()
            return {
                "Equity": float(acc.portfolio_value),
                "Power": float(acc.buying_power),
                "Cash": float(acc.cash)
            }
        except Exception:
            return {}

    def get_orders_for_symbol(self, symbol):
        try:
            orders = self.api.list_orders(status='open', symbols=[symbol])
            return [f"{o.type.upper()} {o.side} @ {o.limit_price or o.stop_price}" for o in orders]
        except Exception:
            return []

    def has_open_order(self, symbol):
        try:
            orders = self.api.list_orders(status='open', symbols=[symbol])
            return len(orders) > 0
        except Exception:
            return True
            
    def is_holding(self, symbol):
        try:
            return self.api.get_position(symbol)
        except Exception:
            return None

    def sell_all(self, sym):
        try:
            pos = self.is_holding(sym)
            if pos:
                self.api.submit_order(symbol=sym, qty=pos.qty, side='sell', type='market', time_in_force='gtc')
        except Exception:
            pass

    # --- UPDATED ORDER FUNCTIONS WITH TCA LOGGING ---

    def _get_snapshot_price(self, symbol):
        """Helper to get current price for logging purposes."""
        try:
            trade = self.api.get_latest_trade(symbol)
            return float(trade.price)
        except:
            return 0.0

    def submit_manual_order(self, symbol, qty, side, type, limit_px=None, stop_px=None, trail_pct=None):
        args = {"symbol": symbol, "qty": qty, "side": side, "type": type, "time_in_force": "gtc"}
        if limit_px: args['limit_price'] = limit_px
        if stop_px: args['stop_price'] = stop_px
        if trail_pct: args['trail_percent'] = trail_pct

        try:
            # 1. Snapshot Price BEFORE submitting
            snap_px = self._get_snapshot_price(symbol)
            
            # 2. Submit
            order = self.api.submit_order(**args)
            
            # 3. Log Attempt
            log_trade_attempt(order.id, symbol, side, qty, type, snap_px)
            
            return True, "Order Submitted"
        except Exception as e:
            return False, str(e)

    def buy_bracket(self, sym, qty, tp_pct, sl_pct):
        try:
            # 1. Snapshot Price
            snap_px = self._get_snapshot_price(sym)
            if snap_px == 0: return # Safety check
            
            # 2. Submit
            order = self.api.submit_order(
                symbol=sym, qty=qty, side='buy', type='market', time_in_force='gtc',
                order_class='bracket',
                take_profit={'limit_price': round(snap_px * (1 + tp_pct), 2)},
                stop_loss={'stop_price': round(snap_px * (1 - sl_pct), 2)}
            )
            
            # 3. Log Attempt
            log_trade_attempt(order.id, sym, 'buy', qty, 'market_bracket', snap_px)
            
        except Exception as e:
            print(f"Bracket Error: {e}")

    def sync_tca_logs(self):
        """Checks pending logs in DB and updates them if they filled."""
        try:
            with sqlite3.connect(DB_PATH) as conn:
                # Find orders that are NEW (unfilled in our DB)
                pending = conn.execute("SELECT order_id FROM trade_execution WHERE status='NEW'").fetchall()
                
            for (oid,) in pending:
                try:
                    # Check Alpaca for status
                    o = self.api.get_order(oid)
                    if o.status == 'filled' and o.filled_avg_price:
                        update_trade_fill(oid, float(o.filled_avg_price), str(o.filled_at))
                    elif o.status in ['canceled', 'expired', 'rejected']:
                         # Mark as dead in DB so we stop checking
                         with sqlite3.connect(DB_PATH) as conn:
                             conn.execute("UPDATE trade_execution SET status=? WHERE order_id=?", (o.status.upper(), oid))
                except:
                    pass
        except Exception as e:
            print(f"TCA Sync Error: {e}")

// src/dashboard.py
import streamlit as st
import pandas as pd
import sqlite3
import time
import json
import plotly.express as px  # NEW: For charts
from src.broker import Broker
from src.database import get_status, update_status, delete_strategy, DB_PATH

# 1. Page Config
st.set_page_config(page_title="Algo Command Center", layout="wide", page_icon="üõ°Ô∏è")

# --- CUSTOM CSS ---
st.markdown("""
<style>
    div.stButton > button { box-shadow: 0px 4px 0px #4a5568; transition: all 0.1s; border: 1px solid #cbd5e0; border-radius: 8px; font-weight: 600; }
    div.stButton > button:active { transform: translateY(4px); box-shadow: none; }
    .paper-badge { background-color: #fffbeb; color: #b7791f; padding: 8px; border: 2px dashed #ecc94b; text-align: center; font-weight: bold; margin-bottom: 15px; }
    .big-metric { font-size: 24px; font-weight: bold; }
</style>
""", unsafe_allow_html=True)

# 2. Broker Init
broker = Broker()
conn_status, conn_msg = broker.test_connection()

# 3. Sidebar
with st.sidebar:
    st.markdown('<div class="paper-badge">‚ö†Ô∏è Alpaca Paper Trading</div>', unsafe_allow_html=True)
    st.title("üì° Overview")
    if conn_status: st.success("üü¢ API ONLINE")
    else: st.error("üî¥ DISCONNECTED")
    
    st.markdown("---")
    acc = broker.get_account_stats()
    st.metric("Buying Power", f"${acc.get('Power', 0):,.2f}")
    st.metric("Cash", f"${acc.get('Cash', 0):,.2f}")
    st.markdown("---")
    hist = broker.get_portfolio_history_stats()
    c1, c2 = st.columns(2); c1.caption("1 Day"); c1.write(hist.get('1D')); c2.caption("1 Week"); c2.write(hist.get('1W'))
    
    st.markdown("---")
    engine_on = get_status("engine_running") == "1"
    if st.button("üõë STOP ENGINE" if engine_on else "üöÄ START ENGINE", use_container_width=True):
        update_status("engine_running", "0" if engine_on else "1")
        st.rerun()

# 4. Header
clock_msg = broker.get_market_clock()
if "üü¢" in clock_msg: st.info(f"**{clock_msg}**")
else: st.warning(f"**{clock_msg}**")

# 5. Tabs (Added 5th Tab)
tab_assets, tab_strat, tab_manual, tab_tca, tab_debug = st.tabs(["üìä Assets", "‚öôÔ∏è Strategies", "üïπÔ∏è Manual", "üìâ Execution (TCA)", "üîç Debug"])

# --- TAB 1: ASSETS ---
with tab_assets:
    try:
        positions = broker.api.list_positions()
        if positions:
            for p in positions:
                pl = float(p.unrealized_pl)
                with st.expander(f"{p.symbol} | {p.qty} sh | P/L: ${pl:.2f}"):
                    c1, c2, c3, c4 = st.columns(4)
                    c1.metric("Price", f"${float(p.current_price):.2f}")
                    c2.metric("Entry", f"${float(p.avg_entry_price):.2f}")
                    c3.metric("Day P/L", f"${float(p.unrealized_intraday_pl):.2f}")
                    c4.metric("Total P/L", f"${pl:.2f}")
        else: st.info("No active positions.")
    except Exception as e: st.error(str(e))

# --- TAB 2: STRATEGIES ---
with tab_strat:
    with sqlite3.connect(DB_PATH) as conn:
        df = pd.read_sql("SELECT * FROM strategies", conn)
        if not df.empty:
            cols = st.columns([1, 1, 1, 1, 1, 1])
            cols[0].markdown("**Symbol**"); cols[3].markdown("TP"); cols[4].markdown("SL")
            st.divider()
            for i, row in df.iterrows():
                try:
                    p = json.loads(row['params'])
                    c = st.columns([1, 1, 1, 1, 1, 1])
                    c[0].markdown(f"**{row['symbol']}**")
                    c[1].caption(f"RSI < {p.get('rsi_trend')}")
                    c[2].caption(f"ADX > {p.get('adx_trend')}")
                    c[3].markdown(f"<span style='color:green'>+{p.get('target',0)*100:.1f}%</span>", unsafe_allow_html=True)
                    c[4].markdown(f"<span style='color:red'>-{p.get('stop',0)*100:.1f}%</span>", unsafe_allow_html=True)
                    if c[5].button("üóëÔ∏è", key=f"d_{row['symbol']}"):
                        delete_strategy(row['symbol']); st.rerun()
                    st.markdown("<hr style='margin:5px 0'>", unsafe_allow_html=True)
                except: pass
        else: st.info("No active strategies.")

# --- TAB 3: MANUAL ---
with tab_manual:
    with st.form("manual"):
        c1, c2, c3, c4 = st.columns(4)
        sym = c1.text_input("Sym", "TSLA"); qty = c2.number_input("Qty", 1.0); side = c3.selectbox("Side", ["buy","sell"]); type = c4.selectbox("Type", ["market","limit","stop"])
        if st.form_submit_button("Submit"):
            ok, msg = broker.submit_manual_order(sym, qty, side, type)
            if ok: st.success(msg); time.sleep(1); st.rerun()
            else: st.error(msg)

# --- TAB 4: TCA (NEW) ---
with tab_tca:
    st.subheader("üìâ Transaction Cost Analysis")
    
    # 1. Sync Button (Trigger syncing with Alpaca)
    if st.button("üîÑ Sync Trade Logs", use_container_width=True):
        with st.spinner("Fetching fill data from Alpaca..."):
            broker.sync_tca_logs()
            st.success("Sync Complete")
            time.sleep(1)
            st.rerun()

    # 2. Fetch Data
    with sqlite3.connect(DB_PATH) as conn:
        df_tca = pd.read_sql("SELECT * FROM trade_execution ORDER BY submitted_at DESC", conn)
    
    if not df_tca.empty:
        # 3. Summary Metrics
        filled = df_tca[df_tca['status'] == 'FILLED']
        
        m1, m2, m3 = st.columns(3)
        total_trades = len(filled)
        avg_slip = filled['slippage_pct'].mean() if not filled.empty else 0.0
        
        m1.metric("Total Fills", total_trades)
        m2.metric("Avg Slippage", f"{avg_slip:.4f}%", delta=-avg_slip, delta_color="inverse")
        m3.caption("Positive Slippage = You paid more than expected (Cost).")

        st.divider()

        # 4. Visual Analysis (Slippage over time)
        if total_trades > 0:
            filled['submitted_at'] = pd.to_datetime(filled['submitted_at'])
            fig = px.scatter(filled, x="submitted_at", y="slippage_pct", 
                             color="side", size="qty", 
                             title="Slippage Distribution (Bubble Size = Qty)",
                             labels={"slippage_pct": "Slippage (%)", "submitted_at": "Time"})
            st.plotly_chart(fig, use_container_width=True)

        # 5. Raw Data Table
        st.markdown("### Trade Logs")
        st.dataframe(df_tca.style.format({
            "snapshot_price": "${:.2f}", 
            "fill_price": "${:.2f}",
            "slippage_pct": "{:.4f}%"
        }), use_container_width=True)
    else:
        st.info("No trade data recorded yet. Place a trade to see analysis.")

# --- TAB 5: DEBUG ---
with tab_debug:
    st.json({"DB": DB_PATH, "API": conn_status})

// src/database.py
import sqlite3
import os
import json
from datetime import datetime

DB_PATH = os.getenv("DB_PATH", "data/trading.db")

def init_db():
    """Initializes the database and ensures all tables exist."""
    os.makedirs(os.path.dirname(DB_PATH), exist_ok=True)
    with sqlite3.connect(DB_PATH) as conn:
        # ... (Existing tables: strategies, system_status, manual_orders) ...
        conn.execute("""
            CREATE TABLE IF NOT EXISTS strategies 
            (symbol TEXT PRIMARY KEY, params TEXT, is_active INTEGER)
        """)
        conn.execute("""
            CREATE TABLE IF NOT EXISTS system_status 
            (key TEXT PRIMARY KEY, value TEXT)
        """)
        conn.execute("""
            CREATE TABLE IF NOT EXISTS manual_orders 
            (id INTEGER PRIMARY KEY AUTOINCREMENT, symbol TEXT, qty REAL, 
             side TEXT, type TEXT, status TEXT DEFAULT 'PENDING')
        """)

        # --- NEW TABLE: Transaction Cost Analysis (TCA) ---
        # Stores the price we WANTED (Snapshot) vs the price we GOT (Fill)
        conn.execute("""
            CREATE TABLE IF NOT EXISTS trade_execution (
                order_id TEXT PRIMARY KEY,
                symbol TEXT,
                side TEXT,
                qty REAL,
                order_type TEXT,
                snapshot_price REAL,  -- Price at moment of logic
                fill_price REAL,      -- Actual execution price
                slippage_pct REAL,    -- (Fill - Snapshot) / Snapshot
                submitted_at TEXT,
                filled_at TEXT,
                status TEXT
            )
        """)
        
        # Insert Default Values
        conn.execute("INSERT OR IGNORE INTO system_status (key, value) VALUES ('engine_running', '1')")
        conn.execute("INSERT OR IGNORE INTO system_status (key, value) VALUES ('api_health', 'Unknown')")
        conn.commit()

# ... (Keep existing update_status, get_status, save_strategy, delete_strategy, get_strategies) ...
def update_status(key, value):
    init_db()  # Defensive check
    with sqlite3.connect(DB_PATH) as conn:
        conn.execute("INSERT OR REPLACE INTO system_status (key, value) VALUES (?, ?)", (key, str(value)))

def get_status(key, default="0"):
    init_db()  # Defensive check
    with sqlite3.connect(DB_PATH) as conn:
        try:
            res = conn.execute("SELECT value FROM system_status WHERE key = ?", (key,)).fetchone()
            return res[0] if res else default
        except sqlite3.OperationalError:
            return default

def save_strategy(symbol, params, is_active):
    init_db()
    with sqlite3.connect(DB_PATH) as conn:
        conn.execute(
            "INSERT OR REPLACE INTO strategies (symbol, params, is_active) VALUES (?, ?, ?)",
            (symbol, json.dumps(params), 1 if is_active else 0)
        )

def delete_strategy(symbol):
    init_db()
    with sqlite3.connect(DB_PATH) as conn:
        conn.execute("DELETE FROM strategies WHERE symbol = ?", (symbol,))

def get_strategies():
    init_db()
    with sqlite3.connect(DB_PATH) as conn:
        rows = conn.execute("SELECT symbol, params FROM strategies").fetchall()
        return {row[0]: json.loads(row[1]) for row in rows}

# --- NEW TCA FUNCTIONS ---
def log_trade_attempt(order_id, symbol, side, qty, type, snapshot_px):
    """Records the intent to trade before we know the result."""
    init_db()
    with sqlite3.connect(DB_PATH) as conn:
        conn.execute("""
            INSERT OR IGNORE INTO trade_execution 
            (order_id, symbol, side, qty, order_type, snapshot_price, submitted_at, status)
            VALUES (?, ?, ?, ?, ?, ?, ?, 'NEW')
        """, (str(order_id), symbol, side, float(qty), type, float(snapshot_px), datetime.utcnow().isoformat()))

def update_trade_fill(order_id, fill_px, filled_at):
    """Updates the record once Alpaca fills it, calculating slippage."""
    init_db()
    with sqlite3.connect(DB_PATH) as conn:
        # Get the original snapshot to calc slippage
        row = conn.execute("SELECT snapshot_price, side FROM trade_execution WHERE order_id=?", (order_id,)).fetchone()
        if row:
            snap_px, side = row
            if snap_px and fill_px:
                # Slippage logic: 
                # Buy: Positive if Fill > Snap (Bad)
                # Sell: Positive if Fill < Snap (Bad)
                diff = fill_px - snap_px
                slip_pct = (diff / snap_px) * 100
                
                # Invert for Sell side so Positive is always "Bad Slippage" (Cost)
                if side == 'sell':
                    slip_pct = slip_pct * -1
                
                conn.execute("""
                    UPDATE trade_execution 
                    SET fill_price=?, filled_at=?, slippage_pct=?, status='FILLED'
                    WHERE order_id=?
                """, (float(fill_px), str(filled_at), float(slip_pct), order_id))

// src/main.py
import schedule
import time
import os
import sqlite3
import json
import subprocess
import numpy as np
import yfinance as yf
import pandas as pd
import pytz
from ta.trend import ADXIndicator
from ta.momentum import RSIIndicator
from src.database import init_db, get_strategies, get_status, update_status, DB_PATH
from src.broker import Broker

# Set Market Timezone to New York (Alpaca's Server Time)
MARKET_TZ = "America/New_York"

def process_manual_queue(broker):
    """Checks database for manual orders placed via Dashboard."""
    try:
        with sqlite3.connect(DB_PATH) as conn:
            orders = conn.execute(
                "SELECT id, symbol, qty, side, type FROM manual_orders WHERE status='PENDING'"
            ).fetchall()
            for o in orders:
                o_id, sym, qty, side, o_type = o
                try:
                    broker.submit_manual_order(sym, qty, side, o_type)
                    conn.execute("UPDATE manual_orders SET status='COMPLETED' WHERE id=?", (o_id,))
                except Exception:
                    conn.execute("UPDATE manual_orders SET status='FAILED' WHERE id=?", (o_id,))
    except Exception as e:
        print(f"Error in manual queue: {e}")


def daily_summary():
    """Prints account stats. Can be extended to send Discord/Email alerts."""
    broker = Broker()
    try:
        stats = broker.get_account_stats()
        perf = broker.get_portfolio_history_stats()
        print(f"Daily Stats: {stats} | Performance: {perf}")
    except Exception:
        pass


def run_reoptimization():
    """Spawns the tuner process to refresh parameters."""
    print("üß† Starting Weekly Re-Optimization...")
    try:
        # NOTE: Ensure you have renamed src/analyzer.py to src/tuner.py
        # If not, change this line to ["python", "src/analyzer.py"]
        subprocess.Popen(["python", "src/tuner.py"])
        print("‚úÖ Optimization started in background")
    except Exception as e:
        print(f"‚ùå Failed to start optimizer: {e}")


def heart_beat():
    """The main logic loop. Runs every minute."""
    # 1. Health signal for Docker
    with open("/tmp/heartbeat", "w") as f:
        f.write(str(time.time()))

    broker = Broker()
    
    # 2. Check API Connection
    try:
        msg = broker.get_market_clock()
        market_open = "üü¢" in msg
        update_status("api_health", msg)
    except Exception:
        update_status("api_health", "üî¥ API DISCONNECTED")
        return

    # 3. Process Manual Orders (Works even if market is closed)
    process_manual_queue(broker)

    # 4. Check Engine Switch
    if get_status("engine_running") == "0":
        return

    # 5. Trading Logic (Only if Market Open)
    if market_open:
        strategies = get_strategies()
        num_symbols = len(strategies) if len(strategies) > 0 else 1

        try:
            account = broker.api.get_account()
            total_equity = float(account.portfolio_value)
            cash_available = float(account.cash)
        except Exception:
            return

        # Equal-Weight Allocation Logic
        target_usd_per_stock = total_equity / num_symbols

        for sym, p in strategies.items():
            # A. Download Data (Threadless for ARM/Docker stability)
            df = yf.download(sym, period="5d", interval="1h", progress=False, threads=False)

            if df.empty:
                continue

            # --- ROBUST SHAPE FIX (Prevents "Data must be 1-dimensional" crash) ---
            # 1. Handle MultiIndex Columns (e.g., Price -> Ticker)
            if isinstance(df.columns, pd.MultiIndex):
                df.columns = df.columns.get_level_values(0)
            
            # 2. Force 1D Series for critical columns
            for c in ["High", "Low", "Close"]:
                if c in df.columns:
                    s = df[c]
                    if isinstance(s, pd.DataFrame):
                        s = s.iloc[:, 0]
                    # Reshape ensures it's strictly a 1D array, then rebuild Series
                    df[c] = pd.Series(np.asarray(s).reshape(-1), index=df.index)
            # ----------------------------------------------------------------------

            # B. Calculate Indicators
            try:
                adx_gen = ADXIndicator(high=df['High'], low=df['Low'], close=df['Close'], window=14)
                rsi_gen = RSIIndicator(close=df['Close'], window=14)

                curr_rsi = rsi_gen.rsi().iloc[-1]
                curr_adx = adx_gen.adx().iloc[-1]
            except Exception as e:
                print(f"‚ö†Ô∏è Indiccalc error {sym}: {e}")
                continue

            # C. Check Status
            is_holding = broker.is_holding(sym)
            has_pending = broker.has_open_order(sym)

            # D. Execution Logic
            
            # üü¢ BUY SIGNAL
            if not is_holding and not has_pending:
                # Retrieve strategy params with defaults
                adx_thresh = p.get('adx_trend', 25)
                rsi_thresh = p.get('rsi_trend', 50)
                
                if curr_adx > adx_thresh and curr_rsi > rsi_thresh:
                    try:
                        current_price = float(broker.api.get_latest_trade(sym).price)
                        allowed_spend = min(target_usd_per_stock, cash_available)
                        qty_to_buy = int(allowed_spend / current_price)

                        if qty_to_buy > 0:
                            print(f"üöÄ BUY SIGNAL: {sym} @ ${current_price}")
                            broker.buy_bracket(sym, qty_to_buy, p['target'], p['stop'])
                            # Deduct cash locally to prevent overspending in same loop
                            cash_available -= (qty_to_buy * current_price)
                    except Exception as e:
                        print(f"‚ùå Buy failed {sym}: {e}")

            # üî¥ SELL SIGNAL (Safety Net)
            # Normal exits are handled by Alpaca Bracket Orders (TP/SL).
            # This is an extra safety check for "Trend Reversal".
            elif is_holding:
                if curr_rsi < 40:
                    print(f"üìâ EXIT SIGNAL: {sym} RSI {curr_rsi:.2f} < 40")
                    broker.sell_all(sym)


if __name__ == "__main__":
    init_db()
    print("üöÄ Algo-Trading Heart Started...")
    
    # 1. Trading Loop
    schedule.every(1).minutes.do(heart_beat)
    
    # 2. Daily Summary (aligned roughly to Market Close)
    schedule.every().day.at("21:00").do(daily_summary)

    # 3. Weekly Auto-Tuner (Sundays at 4 AM)
    schedule.every().sunday.at("04:00").do(run_reoptimization)

    # Run logic once immediately on startup
    heart_beat()

    while True:
        schedule.run_pending()
        time.sleep(1)

// src/tuner.py
import os
import yfinance as yf
import pandas_ta_classic as ta
import optuna
import urllib3
import pandas as pd
import numpy as np
import gc
import shutil
from functools import partial
from src.database import save_strategy, init_db
from src.broker import Broker

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# Tuner operates on the specific list of stocks you want to trade
TICKERS = ['HOOD', 'AMD', 'AI', 'CVNA', 'PLTR']

def get_stock_data(symbol):
    """
    Downloads and cleans data.
    - Fixed: auto_adjust=False (keeps raw OHLC)
    - Fixed: Robust flattening of MultiIndex
    """
    try:
        # Threads=False for ARM/Docker stability
        df = yf.download(symbol, period="1y", interval="1h", 
                         progress=False, threads=False, auto_adjust=False)
        
        if df.empty: return None

        # 1. Fix MultiIndex Columns (Ticker -> Price)
        if isinstance(df.columns, pd.MultiIndex):
            df.columns = df.columns.get_level_values(0)

        # 2. Fix 2D Array Issues (The "Shape" Fix)
        for c in ["Open", "High", "Low", "Close"]:
            if c in df.columns:
                s = df[c]
                if isinstance(s, pd.DataFrame): s = s.iloc[:, 0]
                df[c] = pd.Series(np.asarray(s).reshape(-1), index=df.index)

        return df
    except Exception as e:
        print(f"‚ùå Download failed for {symbol}: {e}")
        return None

def precompute_indicators(df):
    """
    Calculates indicators ONCE before optimization loop.
    - Fixed: Robust ADX column selection
    """
    df = df.copy()
    try:
        # ADX (Directional Movement)
        adx_df = ta.adx(df['High'], df['Low'], df['Close'], length=14)
        if adx_df is None or adx_df.empty: return None
        
        # Find the correct column (ADX_14 or similar)
        adx_col = next((c for c in adx_df.columns if c.startswith("ADX")), None)
        if not adx_col: return None
        
        df['ADX'] = adx_df[adx_col]
        
        # RSI
        df['RSI'] = ta.rsi(df['Close'], length=14)
        
        # Shift indicators so Row 'i' sees the metrics from 'i-1' (No Lookahead)
        df['ADX_Prev'] = df['ADX'].shift(1)
        df['RSI_Prev'] = df['RSI'].shift(1)
        
        df.dropna(inplace=True)
        return df
    except Exception:
        return None

def objective(trial, df):
    """
    Simulates trading with REALISTIC constraints.
    - No Lookahead: Decision made on (i-1), Execution on Open(i)
    - Intra-bar Exits: Check Low vs SL and High vs TP
    """
    # 1. Suggest Parameters
    adx_thresh = trial.suggest_int("adx_trend", 20, 30)
    rsi_thresh = trial.suggest_int("rsi_trend", 45, 60)
    tp_pct = trial.suggest_float("target", 0.10, 0.30)
    sl_pct = trial.suggest_float("stop", 0.05, 0.10)

    # Convert columns to numpy arrays for massive speed boost
    opens = df['Open'].values
    highs = df['High'].values
    lows  = df['Low'].values
    closes = df['Close'].values
    adx_prev = df['ADX_Prev'].values
    rsi_prev = df['RSI_Prev'].values

    # Simulation State
    balance = 1000.0  # Virtual starting cash
    position = 0      # 0 = flat, >0 = shares
    entry_price = 0.0
    
    # 2. Fast Vectorized-Style Loop
    for i in range(len(df)):
        # EXIT LOGIC (If we have a position)
        if position > 0:
            # Check Stop Loss First (Conservative assumption: SL hits before TP)
            stop_price = entry_price * (1 - sl_pct)
            take_price = entry_price * (1 + tp_pct)
            
            # Did we hit SL?
            if lows[i] <= stop_price:
                # We assume we got filled at the stop price (or Open if it gapped down)
                exit_fill = min(opens[i], stop_price)
                balance = position * exit_fill
                position = 0
                continue # Trade over
            
            # Did we hit TP?
            if highs[i] >= take_price:
                # We assume we got filled at target (or Open if it gapped up)
                exit_fill = max(opens[i], take_price)
                balance = position * exit_fill
                position = 0
                continue # Trade over
                
            # Trend Reversal Exit (RSI < 40 safety net)
            # We use the previous closed RSI to decide to sell at Open[i]
            if rsi_prev[i] < 40:
                balance = position * opens[i]
                position = 0
                continue

        # ENTRY LOGIC (If we are flat)
        else:
            # Decision based on PREVIOUS candle (adx_prev, rsi_prev)
            # Execution happens at CURRENT Open
            if adx_prev[i] > adx_thresh and rsi_prev[i] > rsi_thresh:
                entry_price = opens[i]
                position = balance / entry_price # All-in

    # Final MTM (Mark to Market) if still holding
    final_equity = balance if position == 0 else position * closes[-1]
    
    # Return Percentage Return as the Score
    return (final_equity - 1000.0) / 1000.0

def optimize_stock(symbol, broker):
    print(f"üïµÔ∏è Tuning {symbol}...")

    # 1. Get Data
    raw_df = get_stock_data(symbol)
    if raw_df is None or len(raw_df) < 100:
        print(f"‚ùå Insufficient data for {symbol}")
        return

    # 2. Precompute Indicators (Huge Speedup)
    df = precompute_indicators(raw_df)
    if df is None:
        print(f"‚ùå Indicator error for {symbol}")
        return

    # 3. Optimize
    try:
        # Seed=42 ensures that if you run it twice, you get the same 'best' params
        sampler = optuna.samplers.TPESampler(seed=42)
        study = optuna.create_study(direction="maximize", sampler=sampler)

        # Bind the precomputed DF to the objective
        optimization_func = partial(objective, df=df)
        
        # 100 Trials is fast now because we precomputed math
        study.optimize(optimization_func, n_trials=100) 

        print(f"‚úÖ Best for {symbol}: {study.best_params} (Score: {study.best_value:.2%})")

        is_holding = broker.is_holding(symbol)
        save_strategy(symbol, study.best_params, is_holding is not None)

        # Cleanup
        del df
        del raw_df
        del study
        gc.collect()

    except Exception as e:
        print(f"‚ö†Ô∏è Optimization error on {symbol}: {e}")

if __name__ == "__main__":
    init_db()
    broker = Broker()
    
    # Note: We removed the aggressive cache deletion logic.
    # Only delete cache manually if you suspect data corruption.
    
    print("üöÄ Starting AI Parameter Tuning...")
    for t in TICKERS:
        optimize_stock(t, broker)
